{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222af72b-3f7e-495f-a394-251f95e6b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, csv, statistics, math, numpy as np, exifread, geopandas as gpd, pandas as pd, cameratransform as ct\n",
    "from osgeo import gdal, osr\n",
    "from shapely.geometry import Point, Polygon\n",
    "from PIL import Image, ExifTags\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# set the base directory where everything lives\n",
    "base_dir = r\"C:\\Users\\gdlarsen\\Documents\\UAS_survey-JHI_WE_S2\\F1\"\n",
    "out_dir = base_dir\n",
    "\n",
    "# set the subdirectories where the images (img) and flight log (flog) live\n",
    "img_dir = f\"{base_dir}\\\\OUTPUTS\"\n",
    "flog_dir = f\"{base_dir}\\\\FLIGHT RECORD\"\n",
    "\n",
    "# set the subdirectories where the georeferenced images will be output and where the footprints feature will be output\n",
    "imgout_dir = f\"{out_dir}\\\\Georeferenced\"\n",
    "shpout_dir = f\"{out_dir}\\\\Shapefiles\"\n",
    "\n",
    "# create output directories, if necessary\n",
    "os.makedirs(shpout_dir, exist_ok = True)\n",
    "os.makedirs(imgout_dir, exist_ok = True)\n",
    "\n",
    "# Look up the sensor width (mm) of the camera, if you can find it: https://www.dxomark.com/\n",
    "# If you can't find it, use 'unknown', for example: sensor_width = 'unknown'\n",
    "\n",
    "# This can often be pulled from the exifdata if preferred\n",
    "camera_model = \"Sony a6100\"\n",
    "\n",
    "sensor_width_dictionary = {\"Sony a6100\": 23.5,\n",
    "                      \"Canon EOS 5DS R\": 36,\n",
    "                     \"NIKON D810\": 35.9}\n",
    "\n",
    "sensor_width = sensor_width_dictionary[camera_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0b695-0605-4e1b-80cf-34d927a30755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function scrapes chunks of metadata for the Sony a6100\n",
    "# it's the most I could find using native python methods\n",
    "# (i.e. not calling ExifTool or anything else in the background)\n",
    "# could more simply and robustly recode this section to just call and import from exiftool\n",
    "# might be improved with more reading about EXIF structure and targeted tag IDs \n",
    "# https://exiftool.org/TagNames/EXIF.html\n",
    "\n",
    "def scrape_metadata(img):\n",
    "    metadata_package = {}\n",
    "    with Image.open(img) as im:\n",
    "        exif = im.getexif()\n",
    "        exif_data = exif.get_ifd(0x8769)\n",
    "        metadata_chunk1={}\n",
    "        for tag_id in exif_data:\n",
    "            tag = ExifTags.TAGS.get(tag_id, tag_id)\n",
    "            content = [exif_data.get(tag_id)]\n",
    "            if type(content).__name__ == 'IFDRational':\n",
    "                content = float(content)\n",
    "            metadata_chunk1[tag] = content\n",
    "        FunctionExif = \"b'0231'\"\n",
    "        if str(metadata_chunk1['ExifVersion'][0]) != str(FunctionExif):\n",
    "            print(f\"Warning: this function was designed for metadata produced in {FunctionExif} format, not {metadata_chunk1['ExifVersion'][0]}. Proceed with caution, metadata could be broken.\")\n",
    "        del metadata_chunk1['MakerNote'], metadata_chunk1['FlashPixVersion'], metadata_chunk1['FileSource'], metadata_chunk1['SceneType'], metadata_chunk1['ComponentsConfiguration']\n",
    "        if sensor_width == 'unknown':\n",
    "            metadata_chunk1['SensorWidth'] = [float(36*metadata_chunk1['FocalLength'][0]/metadata_chunk1['FocalLengthIn35mmFilm'][0])]\n",
    "        else:\n",
    "            metadata_chunk1['SensorWidth'] = [sensor_width]\n",
    "        metadata_chunk1['FieldOfView'] = [math.degrees(2*math.atan(metadata_chunk1['SensorWidth'][0]/(2*metadata_chunk1['FocalLength'][0])))]\n",
    "        metadata_chunk1['AspectRatio'] = [metadata_chunk1['ExifImageWidth'][0]/metadata_chunk1['ExifImageHeight'][0]]\n",
    "        metadata_package.update(metadata_chunk1)\n",
    "        \n",
    "        metadata_chunk2 = {}\n",
    "        for tag_id in ExifTags.IFD:\n",
    "            ifd = exif.get_ifd(tag_id)\n",
    "            if tag_id == ExifTags.IFD.GPSInfo:\n",
    "                resolve = ExifTags.GPSTAGS\n",
    "                for k, v in ifd.items():\n",
    "                    tag = resolve.get(k, k)\n",
    "                    metadata_chunk2[tag] = [v]\n",
    "        del metadata_chunk2['GPSVersionID'], metadata_chunk2['GPSAltitudeRef']\n",
    "        metadata_chunk2['GPSLongitudeDD'] = [(float(metadata_chunk2['GPSLongitude'][0][0]) + float(metadata_chunk2['GPSLongitude'][0][1])/60 + float(metadata_chunk2['GPSLongitude'][0][2])/(60*60))*(-1 if metadata_chunk2['GPSLongitudeRef'][0] == 'W' else 1)]\n",
    "        metadata_chunk2['GPSLatitudeDD'] = [(float(metadata_chunk2['GPSLatitude'][0][0]) + float(metadata_chunk2['GPSLatitude'][0][1])/60 + float(metadata_chunk2['GPSLatitude'][0][2])/(60*60))*(-1 if metadata_chunk2['GPSLatitudeRef'][0] == 'S' else 1)]\n",
    "        metadata_package.update(metadata_chunk2)\n",
    "\n",
    "        xmpdata = im.getxmp()['xmpmeta']['RDF']['Description']\n",
    "        metadata_chunk3 = xmpdata\n",
    "        metadata_package.update(metadata_chunk3)\n",
    "\n",
    "        FunctionCamera = 'ILCE-6100 v1.00'\n",
    "        if str(metadata_chunk3['CreatorTool']) != str(FunctionCamera):\n",
    "            print(f\"Warning: this function was designed for metadata produced by {FunctionCamera}, not {metadata_chunk3['CreatorTool']}. Proceed with caution, metadata could be broken.\")\n",
    "    return metadata_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a9f7f-2ec2-448b-8565-7a1b95dcfd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section reads the jpgs and extracts the metadata into a table, using the previous function\n",
    "img_list = glob.glob(f\"{base_dir}//*OUTPUT//*.jpg\", recursive=True)\n",
    "\n",
    "# img_list = img_list[355:365] # for demo\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for img in img_list:\n",
    "    image_name = img.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    metadata = scrape_metadata(img)\n",
    "    sensor_size = float(metadata['SensorWidth'][0]), float(metadata['SensorWidth'][0]/metadata['AspectRatio'][0])\n",
    "    metadict = {'ImageName': [image_name], 'ImagePath': [img]}|metadata|{'SensorSize': [sensor_size]}\n",
    "    df = pd.concat([df, pd.DataFrame.from_dict(metadict)])\n",
    "df = df.reset_index()\n",
    "\n",
    "# This section corrects the camera time for timezone/offsets\n",
    "from datetime import datetime as dt\n",
    "\n",
    "if df['OffsetTime'].loc[0][0] == \"+\":\n",
    "    offset_subtraction = True\n",
    "elif df['OffsetTime'].loc[0][0] == \"-\":\n",
    "    offset_subtraction = True\n",
    "else:\n",
    "    print(f\"might need to code for an unsigned offset, value {df['OffsetTime'].loc[0][0]}\")\n",
    "\n",
    "# This code assumes that the time offset is consistent across the flight (reasonable assumption)\n",
    "# If it varies we can recode a vectorized solution.\n",
    "hoffset, moffset = df['OffsetTime'].loc[0][1:].split(\":\")\n",
    "time_mod = pd.to_datetime(df['DateTimeOriginal'], format = \"%Y:%m:%d %H:%M:%S\")\n",
    "if offset_subtraction:\n",
    "    time_mod = time_mod - (pd.offsets.Hour(int(hoffset)) + pd.offsets.Minute(int(moffset)))\n",
    "else:\n",
    "    time_mod = time_mod + (pd.offsets.Hour(int(hoffset)) + pd.offsets.Minute(int(moffset)))\n",
    "df['DateTime(UTC)'] = time_mod\n",
    "print(\"Table created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb69d8d-798a-4b47-bf73-671755f4997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altitude is often unreliable metadata, whether from GPS or barometer.\n",
    "# In this case, from inspecting photos, it's clear that the drone\n",
    "# was closer to the water than GPS measurements represent\n",
    "# so we're merging the drone flight log (based on time) so we can pull the drone altitude\n",
    "\n",
    "# read in the CSV flight log\n",
    "csv_list = glob.glob(f\"{base_dir}//FLIGHT RECORD//*.csv\", recursive=True)\n",
    "ulog_list = glob.glob(f\"{base_dir}//FLIGHT RECORD//*.ulg\", recursive=True)\n",
    "print(f\"Reading log file {csv_list[0]}\")\n",
    "csv_df = pd.read_csv(csv_list[0])\n",
    "\n",
    "altitude_offset = []\n",
    "# format and merge the CSV flight log into our dataframe\n",
    "csv_df = csv_df.rename(columns={'time(epoch)':'DateTime(Epoch)', 'time(UTC)':'DateTime(UTC)', 'lat':'DroneLatitude', 'lon':'DroneLongitude', 'alt':'DroneAltitude'})\n",
    "csv_df['DateTime(UTC)']=pd.to_datetime(csv_df['DateTime(UTC)'], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "new_df = pd.merge(df, csv_df, on = 'DateTime(UTC)')\n",
    "if len(df) != len(new_df):\n",
    "    altitude_offset = statistics.mode(csv_df['DroneAltitude']) - statistics.mode([float(i) for i in df['GPSAltitude']])\n",
    "    print(f\"merged table is a different length than original table, defaulting to GPSAltitude with an offset of {altitude_offset} m\")\n",
    "    df['DroneAltitude'] = \"NA\"\n",
    "    print(\"Drone altitude column populated with NAs\")\n",
    "    # this might happen if not all camera timestamps occur among drone timestamps\n",
    "else:\n",
    "    df = new_df\n",
    "    print(\"Drone altitude merged with table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ba810-35b9-46fe-92e7-a5fd9160ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section reads uses the metadata to generate GCPs for image projection\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for index, metadata in df.iterrows():\n",
    "    # queue up important parameters from the metadata\n",
    "    f = metadata['FocalLength']\n",
    "    sensor_size = metadata['SensorWidth'], metadata['SensorWidth']/metadata['AspectRatio']\n",
    "    image_size = img_w, img_h = metadata['ExifImageWidth'], metadata['ExifImageHeight']\n",
    "    lat, lon = metadata['GPSLatitudeDD'], metadata['GPSLongitudeDD']\n",
    "    if not altitude_offset:\n",
    "        alt = float(metadata['DroneAltitude'])\n",
    "    else:\n",
    "        alt = float(metadata['GPSAltitude']) + altitude_offset\n",
    "\n",
    "    # transform rotation angles from drone's output to cameratransform's input\n",
    "    yaw, pitch, roll = -1*Rotation.from_euler('zxy' ,[float(metadata['Yaw']), float(metadata['Pitch']), float(metadata['Roll'])\n",
    "                                           ], degrees=True).as_euler('zxz', degrees=True)\n",
    "    \n",
    "    # this part took some plug-and-chug troubleshooting\n",
    "    # maybe there's a better solution but I haven't figured it out\n",
    "    yaw, roll = -180-yaw, 180+roll\n",
    "\n",
    "    cam = ct.Camera(ct.RectilinearProjection(focallength_mm = f, sensor = sensor_size, image = image_size),\n",
    "                    ct.SpatialOrientation(elevation_m = alt, tilt_deg = pitch, roll_deg = roll, heading_deg = yaw, \n",
    "                                        pos_x_m = 0, pos_y_m = 0))\n",
    "    \n",
    "    # use cameratransform package to assign spatial values to image locations\n",
    "    cam.setGPSpos(lat, lon, alt)\n",
    "\n",
    "    img_edgepoints = ([0, 0], # top left\n",
    "                      [img_w-1, 0], # top right\n",
    "                      [img_w-1, img_h-1], # bottom right\n",
    "                      [0, img_h-1], # bottom left\n",
    "                 \n",
    "                      [(img_w-1)/2, 0], # top midpoint\n",
    "                      [img_w-1, (img_h-1)/2], # right midpoint\n",
    "                      [(img_w-1)/2, img_h-1], # bottom midpoint\n",
    "                      [0, (img_h-1)/2] # left midpoint\n",
    "                     )\n",
    "    GCP_list = [cam.gpsFromImage(i).tolist()[0:2][::-1] + [0] + i for i in img_edgepoints]\n",
    "\n",
    "    metadict = {'ImageName': metadata['ImageName'], 'GCPList': [GCP_list], 'geometry': [Polygon([i[0:2]for i in GCP_list][0:4])]}\n",
    "    df2 = pd.concat([df2, pd.DataFrame.from_dict(metadict)])\n",
    "\n",
    "gdf = gpd.GeoDataFrame(pd.merge(df, df2, on='ImageName'), crs=\"EPSG:4326\")\n",
    "print(\"GCPs ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50459c82-e028-4262-bd6b-2c3abc5493f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section outputs the geodataframe to a shapefile with all metadata as attributes.\n",
    "# Note that attribute field names get truncated to 10 characters\n",
    "\n",
    "# This section suppresses those warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Normalized/laundered field name\")\n",
    "\n",
    "out_path = f\"{shpout_dir}\\\\Image_footprints.shp\"\n",
    "gdf.to_file(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f033b-e9b6-4fcf-bf2b-b3f5ed1747c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section reads in each image and its GCPs, references and warps the image, then saves it out as a JPEG\n",
    "os.makedirs(imgout_dir, exist_ok = True)\n",
    "\n",
    "# alternative format \"GeoTIFF\" is much larger per file\n",
    "out_format = \"JPEG\"\n",
    "\n",
    "gdal.UseExceptions()\n",
    "\n",
    "for index, record in gdf.iterrows():\n",
    "\n",
    "    # Read in the image file:\n",
    "    ds = gdal.Open(record['ImagePath'])\n",
    "    if ds is None:\n",
    "        print(f\"Could not open image: {record['ImagePath']}\")\n",
    "    # Set spatial reference:\n",
    "    sr = osr.SpatialReference()\n",
    "    sr.ImportFromEPSG(4326)\n",
    "\n",
    "    # Import GCPs\n",
    "    gcps = [gdal.GCP(*i) for i in record['GCPList']]\n",
    "\n",
    "    # Apply the GCPs to the open output file then warp it\n",
    "    ds.SetGCPs(gcps, sr.ExportToWkt())\n",
    "\n",
    "    if out_format==\"JPEG\":\n",
    "        kwargs = {'format': 'JPEG', 'polynomialOrder':2, 'srcNodata': '0,0,0', 'dstNodata': 'nodata'}\n",
    "        ds = gdal.Warp(f\"{imgout_dir}\\\\{record['ImageName']}_GeoRef.jpg\", ds, **kwargs)\n",
    "    elif out_format==\"GeoTIFF\":\n",
    "        kwargs = {'format': 'GTiff', 'polynomialOrder':2, 'srcNodata': '0,0,0', 'dstNodata': 'nodata'}\n",
    "        ds = gdal.Warp(f\"{imgout_dir}\\\\{record['ImageName']}_GeoRef.tif\", ds, **kwargs)\n",
    "    else:\n",
    "        print(fr\"format '{out_format}' not currently supported, code it yourself from https://gdal.org/en/latest/drivers/raster/index.html\")\n",
    "        break\n",
    "    # Clear the variable (not sure if necessary, but good form)\n",
    "    ds = None\n",
    "    # counter, just because it can be a long process\n",
    "    if (index+1) % 10 == 0:\n",
    "        print(f\"Completed file {index+1} out of {len(df)+1}\")\n",
    "print(\"finished processing images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984e63b-cee9-49f3-ae24-a80a208ce5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
